bash tools/simple_test.sh projects/configs/bevformer/bevformer_base.py ckpts/r101_dcn_fcos3d_pretrain.pth

projects.mmdet3d_plugin
WARNING!!!!, Only can be used for obtain inference speed!!!!
/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/bevformer/modules/custom_base_transformer_layer.py:94: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py:341: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py:341: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py:341: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  warnings.warn(
/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
load checkpoint from local path: ckpts/r101_dcn_fcos3d_pretrain.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: bbox_head.bld_alpha, bbox_head.cls_convs.0.conv.weight, bbox_head.cls_convs.0.conv.bias, bbox_head.cls_convs.0.gn.weight, bbox_head.cls_convs.0.gn.bias, bbox_head.cls_convs.1.conv.weight, bbox_head.cls_convs.1.conv.bias, bbox_head.cls_convs.1.conv.conv_offset.weight, bbox_head.cls_convs.1.conv.conv_offset.bias, bbox_head.cls_convs.1.gn.weight, bbox_head.cls_convs.1.gn.bias, bbox_head.reg_convs.0.conv.weight, bbox_head.reg_convs.0.conv.bias, bbox_head.reg_convs.0.gn.weight, bbox_head.reg_convs.0.gn.bias, bbox_head.reg_convs.1.conv.weight, bbox_head.reg_convs.1.conv.bias, bbox_head.reg_convs.1.conv.conv_offset.weight, bbox_head.reg_convs.1.conv.conv_offset.bias, bbox_head.reg_convs.1.gn.weight, bbox_head.reg_convs.1.gn.bias, bbox_head.conv_cls_prev.0.conv.weight, bbox_head.conv_cls_prev.0.conv.bias, bbox_head.conv_cls_prev.0.gn.weight, bbox_head.conv_cls_prev.0.gn.bias, bbox_head.conv_cls.weight, bbox_head.conv_cls.bias, bbox_head.conv_reg_prevs.0.0.conv.weight, bbox_head.conv_reg_prevs.0.0.conv.bias, bbox_head.conv_reg_prevs.0.0.gn.weight, bbox_head.conv_reg_prevs.0.0.gn.bias, bbox_head.conv_reg_prevs.1.0.conv.weight, bbox_head.conv_reg_prevs.1.0.conv.bias, bbox_head.conv_reg_prevs.1.0.gn.weight, bbox_head.conv_reg_prevs.1.0.gn.bias, bbox_head.conv_reg_prevs.2.0.conv.weight, bbox_head.conv_reg_prevs.2.0.conv.bias, bbox_head.conv_reg_prevs.2.0.gn.weight, bbox_head.conv_reg_prevs.2.0.gn.bias, bbox_head.conv_reg_prevs.3.0.conv.weight, bbox_head.conv_reg_prevs.3.0.conv.bias, bbox_head.conv_reg_prevs.3.0.gn.weight, bbox_head.conv_reg_prevs.3.0.gn.bias, bbox_head.conv_reg_prevs.5.0.conv.weight, bbox_head.conv_reg_prevs.5.0.conv.bias, bbox_head.conv_reg_prevs.5.0.gn.weight, bbox_head.conv_reg_prevs.5.0.gn.bias, bbox_head.conv_regs.0.weight, bbox_head.conv_regs.0.bias, bbox_head.conv_regs.1.weight, bbox_head.conv_regs.1.bias, bbox_head.conv_regs.2.weight, bbox_head.conv_regs.2.bias, bbox_head.conv_regs.3.weight, bbox_head.conv_regs.3.bias, bbox_head.conv_regs.4.weight, bbox_head.conv_regs.4.bias, bbox_head.conv_regs.5.weight, bbox_head.conv_regs.5.bias, bbox_head.conv_dir_cls_prev.0.conv.weight, bbox_head.conv_dir_cls_prev.0.conv.bias, bbox_head.conv_dir_cls_prev.0.gn.weight, bbox_head.conv_dir_cls_prev.0.gn.bias, bbox_head.conv_dir_cls.weight, bbox_head.conv_dir_cls.bias, bbox_head.conv_attr_prev.0.conv.weight, bbox_head.conv_attr_prev.0.conv.bias, bbox_head.conv_attr_prev.0.gn.weight, bbox_head.conv_attr_prev.0.gn.bias, bbox_head.conv_attr.weight, bbox_head.conv_attr.bias, bbox_head.conv_depth_cls_prev.0.conv.weight, bbox_head.conv_depth_cls_prev.0.conv.bias, bbox_head.conv_depth_cls_prev.0.gn.weight, bbox_head.conv_depth_cls_prev.0.gn.bias, bbox_head.conv_depth_cls.weight, bbox_head.conv_depth_cls.bias, bbox_head.conv_centerness_prev.0.conv.weight, bbox_head.conv_centerness_prev.0.conv.bias, bbox_head.conv_centerness_prev.0.gn.weight, bbox_head.conv_centerness_prev.0.gn.bias, bbox_head.conv_centerness.weight, bbox_head.conv_centerness.bias, bbox_head.scales.0.0.scale, bbox_head.scales.0.1.scale, bbox_head.scales.0.2.scale, bbox_head.scales.0.3.scale, bbox_head.scales.1.0.scale, bbox_head.scales.1.1.scale, bbox_head.scales.1.2.scale, bbox_head.scales.1.3.scale, bbox_head.scales.2.0.scale, bbox_head.scales.2.1.scale, bbox_head.scales.2.2.scale, bbox_head.scales.2.3.scale, bbox_head.scales.3.0.scale, bbox_head.scales.3.1.scale, bbox_head.scales.3.2.scale, bbox_head.scales.3.3.scale, bbox_head.scales.4.0.scale, bbox_head.scales.4.1.scale, bbox_head.scales.4.2.scale, bbox_head.scales.4.3.scale, img_neck.fpn_convs.4.conv.weight, img_neck.fpn_convs.4.conv.bias

missing keys in source state_dict: pts_bbox_head.code_weights, pts_bbox_head.positional_encoding.row_embed.weight, pts_bbox_head.positional_encoding.col_embed.weight, pts_bbox_head.transformer.level_embeds, pts_bbox_head.transformer.cams_embeds, pts_bbox_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.0.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.0.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.0.norms.0.weight, pts_bbox_head.transformer.encoder.layers.0.norms.0.bias, pts_bbox_head.transformer.encoder.layers.0.norms.1.weight, pts_bbox_head.transformer.encoder.layers.0.norms.1.bias, pts_bbox_head.transformer.encoder.layers.0.norms.2.weight, pts_bbox_head.transformer.encoder.layers.0.norms.2.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.1.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.1.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.1.norms.0.weight, pts_bbox_head.transformer.encoder.layers.1.norms.0.bias, pts_bbox_head.transformer.encoder.layers.1.norms.1.weight, pts_bbox_head.transformer.encoder.layers.1.norms.1.bias, pts_bbox_head.transformer.encoder.layers.1.norms.2.weight, pts_bbox_head.transformer.encoder.layers.1.norms.2.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.2.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.2.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.2.norms.0.weight, pts_bbox_head.transformer.encoder.layers.2.norms.0.bias, pts_bbox_head.transformer.encoder.layers.2.norms.1.weight, pts_bbox_head.transformer.encoder.layers.2.norms.1.bias, pts_bbox_head.transformer.encoder.layers.2.norms.2.weight, pts_bbox_head.transformer.encoder.layers.2.norms.2.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.3.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.3.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.3.norms.0.weight, pts_bbox_head.transformer.encoder.layers.3.norms.0.bias, pts_bbox_head.transformer.encoder.layers.3.norms.1.weight, pts_bbox_head.transformer.encoder.layers.3.norms.1.bias, pts_bbox_head.transformer.encoder.layers.3.norms.2.weight, pts_bbox_head.transformer.encoder.layers.3.norms.2.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.4.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.4.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.4.norms.0.weight, pts_bbox_head.transformer.encoder.layers.4.norms.0.bias, pts_bbox_head.transformer.encoder.layers.4.norms.1.weight, pts_bbox_head.transformer.encoder.layers.4.norms.1.bias, pts_bbox_head.transformer.encoder.layers.4.norms.2.weight, pts_bbox_head.transformer.encoder.layers.4.norms.2.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.0.value_proj.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.0.value_proj.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.0.output_proj.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.0.output_proj.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.sampling_offsets.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.sampling_offsets.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.attention_weights.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.attention_weights.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.value_proj.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.value_proj.bias, pts_bbox_head.transformer.encoder.layers.5.attentions.1.output_proj.weight, pts_bbox_head.transformer.encoder.layers.5.attentions.1.output_proj.bias, pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.weight, pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.bias, pts_bbox_head.transformer.encoder.layers.5.norms.0.weight, pts_bbox_head.transformer.encoder.layers.5.norms.0.bias, pts_bbox_head.transformer.encoder.layers.5.norms.1.weight, pts_bbox_head.transformer.encoder.layers.5.norms.1.bias, pts_bbox_head.transformer.encoder.layers.5.norms.2.weight, pts_bbox_head.transformer.encoder.layers.5.norms.2.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.0.norms.0.weight, pts_bbox_head.transformer.decoder.layers.0.norms.0.bias, pts_bbox_head.transformer.decoder.layers.0.norms.1.weight, pts_bbox_head.transformer.decoder.layers.0.norms.1.bias, pts_bbox_head.transformer.decoder.layers.0.norms.2.weight, pts_bbox_head.transformer.decoder.layers.0.norms.2.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.1.norms.0.weight, pts_bbox_head.transformer.decoder.layers.1.norms.0.bias, pts_bbox_head.transformer.decoder.layers.1.norms.1.weight, pts_bbox_head.transformer.decoder.layers.1.norms.1.bias, pts_bbox_head.transformer.decoder.layers.1.norms.2.weight, pts_bbox_head.transformer.decoder.layers.1.norms.2.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.2.norms.0.weight, pts_bbox_head.transformer.decoder.layers.2.norms.0.bias, pts_bbox_head.transformer.decoder.layers.2.norms.1.weight, pts_bbox_head.transformer.decoder.layers.2.norms.1.bias, pts_bbox_head.transformer.decoder.layers.2.norms.2.weight, pts_bbox_head.transformer.decoder.layers.2.norms.2.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.3.norms.0.weight, pts_bbox_head.transformer.decoder.layers.3.norms.0.bias, pts_bbox_head.transformer.decoder.layers.3.norms.1.weight, pts_bbox_head.transformer.decoder.layers.3.norms.1.bias, pts_bbox_head.transformer.decoder.layers.3.norms.2.weight, pts_bbox_head.transformer.decoder.layers.3.norms.2.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.4.norms.0.weight, pts_bbox_head.transformer.decoder.layers.4.norms.0.bias, pts_bbox_head.transformer.decoder.layers.4.norms.1.weight, pts_bbox_head.transformer.decoder.layers.4.norms.1.bias, pts_bbox_head.transformer.decoder.layers.4.norms.2.weight, pts_bbox_head.transformer.decoder.layers.4.norms.2.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias, pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight, pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias, pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight, pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias, pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight, pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias, pts_bbox_head.transformer.decoder.layers.5.norms.0.weight, pts_bbox_head.transformer.decoder.layers.5.norms.0.bias, pts_bbox_head.transformer.decoder.layers.5.norms.1.weight, pts_bbox_head.transformer.decoder.layers.5.norms.1.bias, pts_bbox_head.transformer.decoder.layers.5.norms.2.weight, pts_bbox_head.transformer.decoder.layers.5.norms.2.bias, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias, pts_bbox_head.transformer.can_bus_mlp.0.weight, pts_bbox_head.transformer.can_bus_mlp.0.bias, pts_bbox_head.transformer.can_bus_mlp.2.weight, pts_bbox_head.transformer.can_bus_mlp.2.bias, pts_bbox_head.transformer.can_bus_mlp.norm.weight, pts_bbox_head.transformer.can_bus_mlp.norm.bias, pts_bbox_head.cls_branches.0.0.weight, pts_bbox_head.cls_branches.0.0.bias, pts_bbox_head.cls_branches.0.1.weight, pts_bbox_head.cls_branches.0.1.bias, pts_bbox_head.cls_branches.0.3.weight, pts_bbox_head.cls_branches.0.3.bias, pts_bbox_head.cls_branches.0.4.weight, pts_bbox_head.cls_branches.0.4.bias, pts_bbox_head.cls_branches.0.6.weight, pts_bbox_head.cls_branches.0.6.bias, pts_bbox_head.cls_branches.1.0.weight, pts_bbox_head.cls_branches.1.0.bias, pts_bbox_head.cls_branches.1.1.weight, pts_bbox_head.cls_branches.1.1.bias, pts_bbox_head.cls_branches.1.3.weight, pts_bbox_head.cls_branches.1.3.bias, pts_bbox_head.cls_branches.1.4.weight, pts_bbox_head.cls_branches.1.4.bias, pts_bbox_head.cls_branches.1.6.weight, pts_bbox_head.cls_branches.1.6.bias, pts_bbox_head.cls_branches.2.0.weight, pts_bbox_head.cls_branches.2.0.bias, pts_bbox_head.cls_branches.2.1.weight, pts_bbox_head.cls_branches.2.1.bias, pts_bbox_head.cls_branches.2.3.weight, pts_bbox_head.cls_branches.2.3.bias, pts_bbox_head.cls_branches.2.4.weight, pts_bbox_head.cls_branches.2.4.bias, pts_bbox_head.cls_branches.2.6.weight, pts_bbox_head.cls_branches.2.6.bias, pts_bbox_head.cls_branches.3.0.weight, pts_bbox_head.cls_branches.3.0.bias, pts_bbox_head.cls_branches.3.1.weight, pts_bbox_head.cls_branches.3.1.bias, pts_bbox_head.cls_branches.3.3.weight, pts_bbox_head.cls_branches.3.3.bias, pts_bbox_head.cls_branches.3.4.weight, pts_bbox_head.cls_branches.3.4.bias, pts_bbox_head.cls_branches.3.6.weight, pts_bbox_head.cls_branches.3.6.bias, pts_bbox_head.cls_branches.4.0.weight, pts_bbox_head.cls_branches.4.0.bias, pts_bbox_head.cls_branches.4.1.weight, pts_bbox_head.cls_branches.4.1.bias, pts_bbox_head.cls_branches.4.3.weight, pts_bbox_head.cls_branches.4.3.bias, pts_bbox_head.cls_branches.4.4.weight, pts_bbox_head.cls_branches.4.4.bias, pts_bbox_head.cls_branches.4.6.weight, pts_bbox_head.cls_branches.4.6.bias, pts_bbox_head.cls_branches.5.0.weight, pts_bbox_head.cls_branches.5.0.bias, pts_bbox_head.cls_branches.5.1.weight, pts_bbox_head.cls_branches.5.1.bias, pts_bbox_head.cls_branches.5.3.weight, pts_bbox_head.cls_branches.5.3.bias, pts_bbox_head.cls_branches.5.4.weight, pts_bbox_head.cls_branches.5.4.bias, pts_bbox_head.cls_branches.5.6.weight, pts_bbox_head.cls_branches.5.6.bias, pts_bbox_head.reg_branches.0.0.weight, pts_bbox_head.reg_branches.0.0.bias, pts_bbox_head.reg_branches.0.2.weight, pts_bbox_head.reg_branches.0.2.bias, pts_bbox_head.reg_branches.0.4.weight, pts_bbox_head.reg_branches.0.4.bias, pts_bbox_head.reg_branches.1.0.weight, pts_bbox_head.reg_branches.1.0.bias, pts_bbox_head.reg_branches.1.2.weight, pts_bbox_head.reg_branches.1.2.bias, pts_bbox_head.reg_branches.1.4.weight, pts_bbox_head.reg_branches.1.4.bias, pts_bbox_head.reg_branches.2.0.weight, pts_bbox_head.reg_branches.2.0.bias, pts_bbox_head.reg_branches.2.2.weight, pts_bbox_head.reg_branches.2.2.bias, pts_bbox_head.reg_branches.2.4.weight, pts_bbox_head.reg_branches.2.4.bias, pts_bbox_head.reg_branches.3.0.weight, pts_bbox_head.reg_branches.3.0.bias, pts_bbox_head.reg_branches.3.2.weight, pts_bbox_head.reg_branches.3.2.bias, pts_bbox_head.reg_branches.3.4.weight, pts_bbox_head.reg_branches.3.4.bias, pts_bbox_head.reg_branches.4.0.weight, pts_bbox_head.reg_branches.4.0.bias, pts_bbox_head.reg_branches.4.2.weight, pts_bbox_head.reg_branches.4.2.bias, pts_bbox_head.reg_branches.4.4.weight, pts_bbox_head.reg_branches.4.4.bias, pts_bbox_head.reg_branches.5.0.weight, pts_bbox_head.reg_branches.5.0.bias, pts_bbox_head.reg_branches.5.2.weight, pts_bbox_head.reg_branches.5.2.bias, pts_bbox_head.reg_branches.5.4.weight, pts_bbox_head.reg_branches.5.4.bias, pts_bbox_head.bev_embedding.weight, pts_bbox_head.query_embedding.weight

[                                                  ] 0/6019, elapsed: 0s, ETA:/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
[                                                  ] 1/6019, 0.7 task/s, elapsed: 2s, ETA:  9086s/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6019/6019, 2.6 task/s, elapsed: 2356s, ETA:     0s
Formating bboxes of pts_bbox
Start to convert detection format...
[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 6019/6019, 14336.0 task/s, elapsed: 0s, ETA:     0s
Results writes to test/bevformer_base/Thu_Aug_10_10_32_16_2023/pts_bbox/results_nusc.json
Evaluating bboxes of pts_bbox
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 29.837 seconds.
======
Reverse indexing ...
Done reverse indexing in 7.7 seconds.
======
Initializing nuScenes detection evaluation
Loaded results from test/bevformer_base/Thu_Aug_10_10_32_16_2023/pts_bbox/results_nusc.json. Found detections for 6019 samples.
Loading annotations for val split from nuScenes version: v1.0-trainval
100%|██████████████████████████████████████████████████████████████████████████████████████████████| 6019/6019 [00:07<00:00, 791.10it/s]
Loaded ground truth annotations for 6019 samples.
Filtering predictions
Traceback (most recent call last):
  File "tools/test.py", line 262, in <module>
    main()
  File "tools/test.py", line 258, in main
    print(dataset.evaluate(outputs, **eval_kwargs))
  File "/home/cairenlan/data_disk/cairenlan/open_source_project/map_segmentation/MapTR/mmdetection3d/mmdet3d/datasets/nuscenes_dataset.py", line 510, in evaluate
    ret_dict = self._evaluate_single(result_files[name])
  File "/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/datasets/nuscenes_dataset.py", line 212, in _evaluate_single
    self.nusc_eval = NuScenesEval_custom(
  File "/home/cairenlan/data_disk/cairenlan/open_source_project/perception/BEVFormer/projects/mmdet3d_plugin/datasets/nuscnes_eval.py", line 570, in __init__
    self.pred_boxes = filter_eval_boxes(nusc, self.pred_boxes, self.cfg.class_range, verbose=verbose)
  File "/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/nuscenes_devkit-1.1.10-py3.8.egg/nuscenes/eval/common/loaders.py", line 219, in filter_eval_boxes
    class_field = _get_box_class_field(eval_boxes)
  File "/home/cairenlan/anaconda3/envs/maptr/lib/python3.8/site-packages/nuscenes_devkit-1.1.10-py3.8.egg/nuscenes/eval/common/loaders.py", line 283, in _get_box_class_field
    raise Exception('Error: Invalid box type: %s' % box)
Exception: Error: Invalid box type: None

